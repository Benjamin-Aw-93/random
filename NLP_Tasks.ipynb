{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "463d9f96-b5e6-466c-b068-7ef5a247bfee",
      "metadata": {
        "id": "463d9f96-b5e6-466c-b068-7ef5a247bfee"
      },
      "source": [
        "# Week 24: Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be78f23",
      "metadata": {
        "id": "4be78f23"
      },
      "source": [
        "## TABLE OF CONTENTS\n",
        "\n",
        "- [Week 24: Natural Language Processing](#Week-24:-Natural-Language-Processing)\n",
        "- [1. Demo: Using TextBlob](#1.-Demo:-Using-TextBlob)\n",
        "  - [1.1 Installation & Import Package](#1.1-Installation-&-Import-Package)\n",
        "  - [1.2 Understanding The blob object](#1.2-Understanding-The-blob-object)\n",
        "    - [Example 1](#Example-1)\n",
        "    - [Example 2](#Example-2)\n",
        "  - [1.3 Part of Speech Tagging](#1.3-Part-of-Speech-Tagging)\n",
        "  - [1.4 Noun Phrases Extraction](#1.4-Noun-Phrases-Extraction)\n",
        "- [1.5 Sentiment Analysis](#1.5-Sentiment-Analysis)\n",
        "  - [1.6 Other Use Methods](#1.6-Other-Use-Methods)\n",
        "    - [1.6.1 Look-up for Definitions](#1.6.1-Look-up-for-Definitions)\n",
        "    - [1.6.2 Look-up for similar terms](#1.6.2-Look-up-for-similar-terms)\n",
        "    - [1.6.3 Spelling Correction](#1.6.3-Spelling-Correction)\n",
        "    - [1.6.4 Language Detection (Optional)](#1.6.4-Language-Detection-(Optional))\n",
        "- [2. Weekly Tasks](#2.-Weekly-Tasks)\n",
        "  - [2.1 Loading the Data](#2.1-Loading-the-Data)\n",
        "  - [2.2 Creating the \"blob\" object for subsequent text analysis](#2.2-Creating-the-\"blob\"-object-for-subsequent-text-analysis)\n",
        "  - [2.3 Understand the Texts - Exploratory Data Analysis](#2.3-Understand-the-Texts---Exploratory-Data-Analysis)\n",
        "  - [2.4 Sentiment Analysis](#2.4-Sentiment-Analysis)\n",
        "  - [2.5 Extracting Features for Descriptive Analysis](#2.5-Extracting-Features-for-Descriptive-Analysis)\n",
        "  - [2.6 Text Classification](#2.6-Text-Classification)\n",
        "    - [2.6.1 Preparing the Data for Classification](#2.6.1-Preparing-the-Data-for-Classification)\n",
        "    - [2.6.2 Train the Classification Model using Scikit-Learn](#2.6.2-Train-the-Classification-Model-using-Scikit-Learn)\n",
        "    - [2.6.3 Extra Contents: Train the Classification Model using TextBlob](#2.6.3-Extra-Contents:-Train-the-Classification-Model-using-TextBlob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82e3e3c-e817-4422-98c5-3b2487e7214b",
      "metadata": {
        "id": "a82e3e3c-e817-4422-98c5-3b2487e7214b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf2f249-bb5b-4c54-8ec2-3dcac79624e4",
      "metadata": {
        "id": "4cf2f249-bb5b-4c54-8ec2-3dcac79624e4"
      },
      "outputs": [],
      "source": [
        "# Settings for Matplotlib (& Seaborn)\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Import libraries for charting\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px #<- NEW\n",
        "\n",
        "# Set the size of charts\n",
        "plt.rc('figure', figsize=(16,9))\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_context(context={'figure.figsize': (16,9)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4370b4a8-1822-4266-8161-b0d26bf20722",
      "metadata": {
        "id": "4370b4a8-1822-4266-8161-b0d26bf20722"
      },
      "outputs": [],
      "source": [
        "# You might need to install ntlk package\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c0c73d-3de7-4685-b71f-c003ddb8e05f",
      "metadata": {
        "id": "15c0c73d-3de7-4685-b71f-c003ddb8e05f"
      },
      "source": [
        "# 1. Demo: Using TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1923a35-6971-491b-bf84-5ec347362ad7",
      "metadata": {
        "id": "e1923a35-6971-491b-bf84-5ec347362ad7"
      },
      "source": [
        "## 1.1 Installation & Import Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b1b4f4-7bf4-4327-b104-c7c26e4c22ce",
      "metadata": {
        "id": "49b1b4f4-7bf4-4327-b104-c7c26e4c22ce"
      },
      "outputs": [],
      "source": [
        "!pip install textblob\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b7464c-4a61-40e7-96d1-788a5feb164a",
      "metadata": {
        "id": "e5b7464c-4a61-40e7-96d1-788a5feb164a"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffff360a-72ab-4ed3-8fb3-b66874122570",
      "metadata": {
        "id": "ffff360a-72ab-4ed3-8fb3-b66874122570"
      },
      "source": [
        "## 1.2 Understanding The blob object "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e56a8e-952e-4ac8-9f69-3833e8e67d2f",
      "metadata": {
        "id": "d3e56a8e-952e-4ac8-9f69-3833e8e67d2f"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d7a13d-7e7e-43fa-97e1-8eca4e8669d6",
      "metadata": {
        "id": "77d7a13d-7e7e-43fa-97e1-8eca4e8669d6"
      },
      "outputs": [],
      "source": [
        "# Example 1\n",
        "text = 'Data Champions bootcamp is a 6-month training course'\n",
        "\n",
        "blob = TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0cf9f83-2c2b-4637-ab06-f342dddb7de4",
      "metadata": {
        "id": "f0cf9f83-2c2b-4637-ab06-f342dddb7de4"
      },
      "outputs": [],
      "source": [
        "# blob has access to many \"string\" methods, just like Python string object\n",
        "print(blob.lower())\n",
        "\n",
        "print(blob.title())\n",
        "\n",
        "print(blob.starts_with(\"Data\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e6054f-1413-4e46-ad8a-ec14c8c14642",
      "metadata": {
        "id": "a2e6054f-1413-4e46-ad8a-ec14c8c14642"
      },
      "source": [
        "### Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbb828b-971e-44c1-a21c-c46af5c21cbb",
      "metadata": {
        "tags": [],
        "id": "7dbb828b-971e-44c1-a21c-c46af5c21cbb"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "\n",
        "text = \"In DC Bootcamp, high-quality e-learning courses are coupled with practical workshops conducted by trainers.\\\n",
        "    Participants will have access to additional learning materials, hands-on tasks, templates,\\\n",
        "    and expose to tools that are contextualized. \\\n",
        "    Officers will learn alongside with a community of like-minded officers and have great opportunity to exchange ideas.\"\n",
        "\n",
        "blob = TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d56856-71d4-40c6-82fe-d383c69d65c1",
      "metadata": {
        "id": "05d56856-71d4-40c6-82fe-d383c69d65c1"
      },
      "outputs": [],
      "source": [
        "# WordList object works like Python's list object. They share similar methods and are iterable.\n",
        "blob.words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d98de1f6-5300-4e0e-8f0c-656b405e8f27",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "d98de1f6-5300-4e0e-8f0c-656b405e8f27"
      },
      "outputs": [],
      "source": [
        "# sentences produces a list of \"Sentence\" objects. They behave similar to \"Word\" object in TextBlob\n",
        "# and share similar methods\n",
        "blob.sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2705cb-5a09-49a6-ba40-c8e73cd3d34c",
      "metadata": {
        "id": "bd2705cb-5a09-49a6-ba40-c8e73cd3d34c"
      },
      "outputs": [],
      "source": [
        "for sentence in blob.sentences:\n",
        "    print(sentence.string)\n",
        "    print(\"\\n\") #next line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9ec159-94a6-4ea6-bc5b-ef4f9ef63ca8",
      "metadata": {
        "id": "0b9ec159-94a6-4ea6-bc5b-ef4f9ef63ca8"
      },
      "source": [
        "## 1.3 Part of Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52e3f86-4c75-496b-8da8-0195be2ad5d8",
      "metadata": {
        "id": "d52e3f86-4c75-496b-8da8-0195be2ad5d8"
      },
      "outputs": [],
      "source": [
        "text = 'Data Champions bootcamp is a 6-month training course'\n",
        "\n",
        "blob = TextBlob(text)\n",
        "blob.pos_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad039f8-1d74-4c65-90bb-73b9ac2d66c1",
      "metadata": {
        "id": "9ad039f8-1d74-4c65-90bb-73b9ac2d66c1"
      },
      "source": [
        "## 1.4 Noun Phrases Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e16514-af00-461b-a8de-1506e9c5e798",
      "metadata": {
        "id": "c2e16514-af00-461b-a8de-1506e9c5e798"
      },
      "outputs": [],
      "source": [
        "blob.noun_phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bbd7f8-ff1d-4399-b3a7-159aba3c1906",
      "metadata": {
        "id": "02bbd7f8-ff1d-4399-b3a7-159aba3c1906"
      },
      "source": [
        "# 1.5 Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e391985c-8790-41dc-9cfa-7ac403771fe4",
      "metadata": {
        "id": "e391985c-8790-41dc-9cfa-7ac403771fe4"
      },
      "outputs": [],
      "source": [
        "\n",
        "text = \"This service is amazingly simple to use. Great to know this!\"\n",
        "\n",
        "blob = TextBlob(text)\n",
        "blob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be259f5-8329-419b-a17c-8cee07160569",
      "metadata": {
        "id": "9be259f5-8329-419b-a17c-8cee07160569"
      },
      "outputs": [],
      "source": [
        "print(\"Polarity = \", blob.sentiment.polarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a2af69-4fad-47cf-99b3-d61f6d7fc136",
      "metadata": {
        "id": "83a2af69-4fad-47cf-99b3-d61f6d7fc136"
      },
      "source": [
        "## 1.6 Other Use Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ac1187-529f-4d43-9c05-571ddaa0c293",
      "metadata": {
        "id": "55ac1187-529f-4d43-9c05-571ddaa0c293"
      },
      "source": [
        "### 1.6.1 Look-up for Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c878625b-8428-46e6-b428-9fb71a26da2f",
      "metadata": {
        "id": "c878625b-8428-46e6-b428-9fb71a26da2f"
      },
      "outputs": [],
      "source": [
        "from textblob import Word\n",
        "\n",
        "myword = Word(\"citizen\")\n",
        "myword.definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1656cc04-c33a-4b76-ab61-ec7e0764dda0",
      "metadata": {
        "tags": [],
        "id": "1656cc04-c33a-4b76-ab61-ec7e0764dda0"
      },
      "source": [
        "### 1.6.2 Look-up for similar terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c34bead-274a-4aac-90c2-cef0ea6f8c81",
      "metadata": {
        "id": "0c34bead-274a-4aac-90c2-cef0ea6f8c81"
      },
      "outputs": [],
      "source": [
        "myword = Word(\"upset\")\n",
        "from textblob.wordnet import ADJ\n",
        "myword.definitions\n",
        "\n",
        "synonyms = set()\n",
        "for synset in myword.get_synsets(pos=ADJ):\n",
        "    for lemma in synset.lemmas():\n",
        "        synonyms.add(lemma.name())\n",
        "        \n",
        "print(synonyms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c071b3be-ff24-4c54-8497-0ac1c8d9a50d",
      "metadata": {
        "tags": [],
        "id": "c071b3be-ff24-4c54-8497-0ac1c8d9a50d"
      },
      "source": [
        "### 1.6.3 Spelling Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5ad971-5ba1-4bd7-a592-981ea44088f9",
      "metadata": {
        "id": "9b5ad971-5ba1-4bd7-a592-981ea44088f9"
      },
      "outputs": [],
      "source": [
        "text = \"I tink the analysis is goood\"\n",
        "\n",
        "blob = TextBlob(text)\n",
        "blob.correct()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ab7de6-bba8-4c39-9a1d-5bde2de73073",
      "metadata": {
        "tags": [],
        "id": "55ab7de6-bba8-4c39-9a1d-5bde2de73073"
      },
      "source": [
        "### 1.6.4 Language Detection (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd5040d0-3008-42fc-871c-5c0263951714",
      "metadata": {
        "scrolled": true,
        "id": "bd5040d0-3008-42fc-871c-5c0263951714"
      },
      "outputs": [],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bdbd6a-3b21-486c-8dc9-3ebbc961a38f",
      "metadata": {
        "id": "53bdbd6a-3b21-486c-8dc9-3ebbc961a38f"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect\n",
        "\n",
        "text = \"I tink the analysis is goood\"\n",
        "detect(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdaf11b-779c-4f02-99e3-d1ac3ae35f92",
      "metadata": {
        "id": "cbdaf11b-779c-4f02-99e3-d1ac3ae35f92"
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61c8ad7a-670d-481f-8f9e-02ba9651edd1",
      "metadata": {
        "tags": [],
        "id": "61c8ad7a-670d-481f-8f9e-02ba9651edd1"
      },
      "source": [
        "# 2. Weekly Tasks "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7290307-8c08-4693-998f-184b0a7b8019",
      "metadata": {
        "id": "a7290307-8c08-4693-998f-184b0a7b8019"
      },
      "source": [
        "## 2.1 Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645313db-fa0d-418a-8683-bab142ce767e",
      "metadata": {
        "id": "645313db-fa0d-418a-8683-bab142ce767e"
      },
      "source": [
        "We will use the same dataset [Yelp Reviews](https://www.kaggle.com/c/yelp-recsys-2013) from the Udemy course.\n",
        "\n",
        "- Each observation in this dataset is a review of a particular business by a particular user.\n",
        "\n",
        "- The \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
        "\n",
        "- The \"cool\" column is the number of \"cool\" votes this review received from other Yelp users. \n",
        "\n",
        "- All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
        "\n",
        "- The \"useful\" and \"funny\" columns are similar to the \"cool\" column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c496c5-b217-40c0-98fa-fd2720400461",
      "metadata": {
        "id": "e1c496c5-b217-40c0-98fa-fd2720400461"
      },
      "outputs": [],
      "source": [
        "link = \"https://raw.githubusercontent.com/Benjamin-Aw-93/random/main/yelp.csv\"\n",
        "\n",
        "df = pd.read_csv(link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2149122-eb4b-4a35-a8bf-3bc377fcc6f9",
      "metadata": {
        "id": "e2149122-eb4b-4a35-a8bf-3bc377fcc6f9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b66b4a-384a-4733-867d-0324a2435547",
      "metadata": {
        "id": "16b66b4a-384a-4733-867d-0324a2435547"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb3eab5-019e-4a54-b1f5-83fdc8861103",
      "metadata": {
        "id": "3fb3eab5-019e-4a54-b1f5-83fdc8861103"
      },
      "outputs": [],
      "source": [
        "df.groupby('business_id').size().describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "426b0189-05ff-4683-8307-6671392d69f8",
      "metadata": {
        "id": "426b0189-05ff-4683-8307-6671392d69f8"
      },
      "outputs": [],
      "source": [
        "df.stars.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d1c0e5-7f0c-49a7-a18d-a26cb0f7ba95",
      "metadata": {
        "id": "e1d1c0e5-7f0c-49a7-a18d-a26cb0f7ba95"
      },
      "outputs": [],
      "source": [
        "df = df[(df['stars'] <=2) | (df['stars'] == 5)]\n",
        "df = df.reset_index(drop=True)\n",
        "len(df) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a56f7c0-b859-4e94-b2a1-f60f7d5ed3f6",
      "metadata": {
        "id": "8a56f7c0-b859-4e94-b2a1-f60f7d5ed3f6"
      },
      "source": [
        "## 2.2 Creating the \"blob\" object for subsequent text analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf1f5e0-d47d-4217-aaae-9a91b14dbc61",
      "metadata": {
        "id": "3bf1f5e0-d47d-4217-aaae-9a91b14dbc61"
      },
      "source": [
        "ðŸ”¶ Reference Code\n",
        "\n",
        "> This is a demo code for your reference.\\\n",
        "> The patterns shown here are also useful for some of the subsequent tasks.\\\n",
        "> Create a new Column **\"blob\"** to store *blob* object from the **\"text\"** of each records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c395873c-ccfb-4361-b0fd-01909577a3e2",
      "metadata": {
        "id": "c395873c-ccfb-4361-b0fd-01909577a3e2"
      },
      "outputs": [],
      "source": [
        "# Alternative 1: Using .apply() \n",
        "def create_blob(row):\n",
        "    comment_text = row['text']\n",
        "    blob_object = TextBlob(comment_text)\n",
        "    return blob_object\n",
        "\n",
        "df['blob'] = df.apply(create_blob, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e661dd-acba-48ac-a2a1-a3324bd08670",
      "metadata": {
        "id": "14e661dd-acba-48ac-a2a1-a3324bd08670"
      },
      "outputs": [],
      "source": [
        "# Alternative 2 (for reference): Using .map() and lambda\n",
        "df['blob'] = df['text'].map(TextBlob)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54589ff7-98ba-4a8c-847c-b2e13736f8bc",
      "metadata": {
        "id": "54589ff7-98ba-4a8c-847c-b2e13736f8bc"
      },
      "source": [
        "## 2.3 Understand the Texts - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32af0d2b-ea16-4c2a-9fd2-fee4cdefabb3",
      "metadata": {
        "id": "32af0d2b-ea16-4c2a-9fd2-fee4cdefabb3"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create a new Column **\"charc_count\"** to store the number of characters in the **\"text\"**.\\\n",
        "> For this task, do count empty space as a character.\\\n",
        "> ðŸ’¡hint: you don't need to use blob (or TextBlob) for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15627222-0c6f-4e30-9883-e1bdb9753e51",
      "metadata": {
        "id": "15627222-0c6f-4e30-9883-e1bdb9753e51"
      },
      "outputs": [],
      "source": [
        "df['charc_count'] = <..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77bdc2d-97ab-4d07-a87b-44fc50519bb6",
      "metadata": {
        "id": "e77bdc2d-97ab-4d07-a87b-44fc50519bb6"
      },
      "outputs": [],
      "source": [
        "df['charc_count'].hist(bins=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987d9f81-4451-4d9c-b4eb-32fa9dc0f94a",
      "metadata": {
        "id": "987d9f81-4451-4d9c-b4eb-32fa9dc0f94a"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create a new Column \"words_count\" to store the number of words in the **\"text\"**\n",
        ">\n",
        "> ðŸ’¡hint: you may use **.words** property from the blob objects stored in your current df.\\\n",
        ">   You can also safely assume words are separated by a space in between."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d07ead91-5d97-483f-a3f3-b3591ba0a1ce",
      "metadata": {
        "id": "d07ead91-5d97-483f-a3f3-b3591ba0a1ce"
      },
      "outputs": [],
      "source": [
        "df['words_count'] = <..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945f0cfd-2027-4f02-aaa1-8b1a0cdc6ecd",
      "metadata": {
        "id": "945f0cfd-2027-4f02-aaa1-8b1a0cdc6ecd"
      },
      "outputs": [],
      "source": [
        "df['words_count'].hist(bins=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3275eacd-355f-4140-8bd7-77433779694f",
      "metadata": {
        "id": "3275eacd-355f-4140-8bd7-77433779694f"
      },
      "source": [
        "## 2.4 Sentiment Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0690185-faaa-43fb-b704-af254553bf34",
      "metadata": {
        "id": "d0690185-faaa-43fb-b704-af254553bf34"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create two new columns:\n",
        ">> A) **\"senti_label\"** - to store the either \"negative\", \"neutral\", or \"positve\" for the comment in  **\"text\"** column. \n",
        "        >>> - 0 = Neutral\n",
        "        >>> - larger than 0 = Positive\n",
        "        >>> - smaller than 0 = Negative\n",
        "        \n",
        ">> B) **\"senti_score\"** - to store the \"polarity\" for the comment in  **\"text\"** column.\n",
        "    \n",
        "> ðŸ’¡hint: use **.sentiment.polarity** of the blob objects created in the current df.\\\n",
        "> You can create two different functions and used them with the .apply() method of a DataFrame.\\\n",
        "> OPTIONAL: Try to write one function (to be used wtih the .apply() method to achieve this if possible. You can also use any other method to create the two columns required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10143dc4-e8b9-43a7-b2a4-45a0d028c3d6",
      "metadata": {
        "id": "10143dc4-e8b9-43a7-b2a4-45a0d028c3d6"
      },
      "outputs": [],
      "source": [
        "def insert_senti_label(row):\n",
        "    <..>\n",
        "\n",
        "df['senti_label'] = df.apply(insert_senti_label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669c91aa-ee71-42f4-8dfa-bbbbd4423724",
      "metadata": {
        "id": "669c91aa-ee71-42f4-8dfa-bbbbd4423724"
      },
      "outputs": [],
      "source": [
        "def insert_senti_score(row):\n",
        "    <..>\n",
        "\n",
        "df['senti_score'] = df.apply(insert_senti_score, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8c08d7-3a5b-4c50-90d3-f760bb0ca739",
      "metadata": {
        "tags": [],
        "id": "8d8c08d7-3a5b-4c50-90d3-f760bb0ca739"
      },
      "source": [
        "## 2.5 Extracting Features for Descriptive Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee9779ca-4b44-4175-99e0-b6d7952b82c6",
      "metadata": {
        "id": "ee9779ca-4b44-4175-99e0-b6d7952b82c6"
      },
      "source": [
        "ðŸ”¶ Reference Code\n",
        "\n",
        "> This is a demo code for your reference.\\\n",
        "> The patterns shown here are also useful for some of the subsequent tasks.\\\n",
        "\n",
        "> Extract the **adjectives** from the **\"text\"** and create a DataFrame with the relevant info (see output).\\\n",
        "> ðŸ’¡hint: you can use the \"tags\" property of the blob object.\\\n",
        "> The tags for \"adjective\" are \"JJ\", \"JJR\", \"JJS\". You can refer to the note of the week for full reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24688ae9-e272-40d6-90e0-dbdedf4b6322",
      "metadata": {
        "id": "24688ae9-e272-40d6-90e0-dbdedf4b6322"
      },
      "outputs": [],
      "source": [
        "# A custom function that will be plugged into the .apply() method\n",
        "def get_adjective_list(row):\n",
        "    df_adjective_partial = None\n",
        "    data_for_each_new_row = []\n",
        "    \n",
        "    part_of_speech_tags = row['blob'].tags\n",
        "    \n",
        "    # Iterate through each of the Part of Speech Tags\n",
        "    for word_tag_pair in part_of_speech_tags:\n",
        "        word = word_tag_pair[0]  # first element is the word\n",
        "        tag = word_tag_pair[1] # second element is the tag\n",
        "        \n",
        "        if tag in ['JJ', 'JJR', 'JJS']:\n",
        "            # append the data related to this \"adjective\" word with other relevant fields\n",
        "            # note: we append a dictionary\n",
        "            data_for_each_new_row.append(\n",
        "                {\n",
        "                    'review_id': row['review_id'],\n",
        "                    'stars': row['stars'], \n",
        "                    'senti_label': row['senti_label'], \n",
        "                    'senti_score': row['senti_score'],\n",
        "                    'adjective': word.lower()\n",
        "                }\n",
        "            )\n",
        "    # for each original row, create a DataFrame for its adjectives (1 adjective 1 row)\n",
        "    df_adjective_partial = pd.DataFrame(data_for_each_new_row)\n",
        "    return df_adjective_partial\n",
        "\n",
        "# Use the .apply method, it return a Series of DataFrames (1 DataFrame per each row)\n",
        "df_adjective = df.apply(get_adjective_list, axis=1)\n",
        "\n",
        "# Concat the DataFrames into final DataFrame\n",
        "df_adjective = pd.concat(list(df_adjective), axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39846610-57ba-4696-a120-e91aa5422aeb",
      "metadata": {
        "id": "39846610-57ba-4696-a120-e91aa5422aeb"
      },
      "outputs": [],
      "source": [
        "# Aggregating the key fields for each \"adjetive\" word\n",
        "grp_adjective = df_adjective.groupby('adjective').agg({'review_id':'count', 'stars':'mean', 'senti_score':'mean'}).reset_index()\n",
        "grp_adjective = grp_adjective.sort_values(['review_id'], axis=0, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed83475-922a-427e-9e4f-dd0034c5c7f5",
      "metadata": {
        "id": "0ed83475-922a-427e-9e4f-dd0034c5c7f5"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(grp_adjective.iloc[:101], x='senti_score', y='stars', size='review_id', text='adjective', color='senti_score', )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1080,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da56e9a3-f920-4c89-8364-d8baa07ac2b7",
      "metadata": {
        "id": "da56e9a3-f920-4c89-8364-d8baa07ac2b7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f9985bd-c2ba-4c9c-949b-c7d48eb88fd0",
      "metadata": {
        "id": "9f9985bd-c2ba-4c9c-949b-c7d48eb88fd0"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Extract the **Noun Phrases** from the **\"text\"** column into a new DataFrame **df_noun_phrases**.\n",
        "> **Each of the Noun Phrase** should be in a single row.\n",
        "> The new DataFrame should contains the follow fields:\n",
        "> - review_id\n",
        "> - stars\n",
        "> - cools\n",
        "> - useful\n",
        "> - funny\n",
        "> - senti_label\n",
        "> - senti_score\n",
        "> - noun_phrase\n",
        "\n",
        "> ðŸ’¡ hint: you can refer to the \"Reference Code\" in Section 2.5 of this Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ab7cdf-3ad5-453a-b900-64f9d72b214a",
      "metadata": {
        "id": "c5ab7cdf-3ad5-453a-b900-64f9d72b214a"
      },
      "outputs": [],
      "source": [
        "def get_noun_phrases(row):\n",
        "    <..>\n",
        "\n",
        "df_noun_phrases = df.apply(<..>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce6b0c74-41ac-4ad0-9e9d-a2fc32f76640",
      "metadata": {
        "id": "ce6b0c74-41ac-4ad0-9e9d-a2fc32f76640"
      },
      "outputs": [],
      "source": [
        "df_noun_phrases = pd.concat(<..>)\n",
        "df_noun_phrases.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7086c71f-8e44-4521-8e7e-1aaa56d788e8",
      "metadata": {
        "id": "7086c71f-8e44-4521-8e7e-1aaa56d788e8"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create an aggregated DataFrame **\"grp_noun_phrases\"** as shown in the screenshot below:\n",
        "> - **noun_phrase**: column with unique noun_phrase \n",
        "> - **record_num**: number of reviews with this noun_phrase\n",
        "> - **stars**: average of \"stars\" of those reviews with this noun_phrase\n",
        "> - **useful**: average of \"useful\" of those reviews with this noun_phrase\n",
        "> - **senti_score**: average of \"senti_score\" of those reviews with this noun_phrase\n",
        "\n",
        "> ðŸ’¡ hint: you can refer to the \"Reference Code\" in Section 2.5 of this Notebook\n",
        "\n",
        "---\n",
        "> ðŸ–¼ï¸ Screenshot Below\\\n",
        "> ![](group.png)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd42b12-755c-4cae-8560-236a34158c8f",
      "metadata": {
        "id": "bcd42b12-755c-4cae-8560-236a34158c8f"
      },
      "outputs": [],
      "source": [
        "grp_noun_phrases = <..>\n",
        "\n",
        "<..>\n",
        "<..>\n",
        "grp_noun_phrases.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713a2386-bd2a-4ba3-9e66-65d72db06d2e",
      "metadata": {
        "id": "713a2386-bd2a-4ba3-9e66-65d72db06d2e"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create a scatter plot that shows the top 100 most frequent noun_phrase\n",
        "> - x-axis is the average \"senti score\"\n",
        "> - y-axis is the average \"stars\"\n",
        "> - size of each data points is presenting the number of records\n",
        "> - color of each data points is presenting the avarage \"useful\"\n",
        "\n",
        "> ðŸ“ Insert your main Observations in the cell below\n",
        "\n",
        "> ðŸ’¡ hint: you can refer to the \"Reference Code\" in Section 2.5 of this Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1d4d53-00b7-450d-a1d3-97e12ee8f56f",
      "metadata": {
        "id": "ae1d4d53-00b7-450d-a1d3-97e12ee8f56f"
      },
      "outputs": [],
      "source": [
        "# Insert 3 of your main Observations Here\n",
        "<..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa495a15-67cb-4691-a21b-d21e57f3a872",
      "metadata": {
        "id": "fa495a15-67cb-4691-a21b-d21e57f3a872"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(<..>)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1080,\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "019a025c-d0a1-4870-b0aa-dcb010d99771",
      "metadata": {
        "id": "019a025c-d0a1-4870-b0aa-dcb010d99771"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Create a scatter plot that shows the top 100 most frequent noun_phrase\\\n",
        "> This time, you are free to choose the column to be used for:\n",
        "> - X and Y axes\n",
        "> - Color and Size of Data Points\n",
        "\n",
        "\n",
        "> ðŸ“ Insert your main Observations in the cell below\n",
        "\n",
        "> ðŸ’¡ hint: you can refer to the \"Reference Code\" in Section 2.5 of this Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fbf6b7-de70-4a32-be76-a70ac13e7bf2",
      "metadata": {
        "id": "e9fbf6b7-de70-4a32-be76-a70ac13e7bf2"
      },
      "outputs": [],
      "source": [
        "# Insert 3 of your main Observations Here\n",
        "<..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397a8098-7fc8-4b43-ad27-48bca3fdc74a",
      "metadata": {
        "id": "397a8098-7fc8-4b43-ad27-48bca3fdc74a"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(<..>)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1080,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5ee281-548f-40e8-8ba6-56710135d8da",
      "metadata": {
        "id": "2e5ee281-548f-40e8-8ba6-56710135d8da"
      },
      "source": [
        "## 2.6 Text Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11fe7221-332c-45ee-9a83-38ffd559f336",
      "metadata": {
        "tags": [],
        "id": "11fe7221-332c-45ee-9a83-38ffd559f336"
      },
      "source": [
        "### 2.6.1 Preparing the Data for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a827b6c3-db41-4497-bb02-8a1640a3dc37",
      "metadata": {
        "id": "a827b6c3-db41-4497-bb02-8a1640a3dc37"
      },
      "outputs": [],
      "source": [
        "# Alternative A:\n",
        "def insert_adjectives_separated_by_comma(row):\n",
        "    list_of_adjectives = []\n",
        "    \n",
        "    part_of_speech_tags = row['blob'].tags\n",
        "    \n",
        "    # Iterate through each of the Part of Speech Tags\n",
        "    for word_tag_pair in part_of_speech_tags:\n",
        "        word = word_tag_pair[0]  # first element is the word\n",
        "        tag = word_tag_pair[1] # second element is the tag\n",
        "        \n",
        "        if tag in ['JJ', 'JJR', 'JJS']:\n",
        "            list_of_adjectives.append(word)\n",
        "    return ', '.join(list_of_adjectives)\n",
        "\n",
        "\n",
        "df['adjectives'] = df.apply(insert_adjectives_separated_by_comma, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93d3019-316c-45f2-a52b-9d936e045bec",
      "metadata": {
        "id": "f93d3019-316c-45f2-a52b-9d936e045bec"
      },
      "outputs": [],
      "source": [
        "# Optional Challenge: Try to Figure out how this code works\n",
        "# It works the same as Alternative A above\n",
        "df['adjectives'] = df.blob.map(lambda x: ', '.join([p[0].lower() for p in x.tags if p[1] in ['JJ', 'JJR', 'JJS']]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191ff601-b5f4-4ed6-a474-62b18990a63b",
      "metadata": {
        "tags": [],
        "id": "191ff601-b5f4-4ed6-a474-62b18990a63b"
      },
      "outputs": [],
      "source": [
        "# Prepareing the Target\n",
        "df['target'] = df.stars >= 4\n",
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af6b2ea8-4ba3-414f-bcb5-c67ac664f458",
      "metadata": {
        "id": "af6b2ea8-4ba3-414f-bcb5-c67ac664f458"
      },
      "source": [
        "### 2.6.2 Train the Classification Model using Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28160e8-ed4b-442a-bf33-7f008cb6a199",
      "metadata": {
        "id": "b28160e8-ed4b-442a-bf33-7f008cb6a199"
      },
      "source": [
        "\n",
        "ðŸ”·**TASK**\n",
        "\n",
        "> Train a **\"MultinomialNB\"** classification model to predict the target.\\\n",
        "> Use the column \"adjectives\" as your input (X)\n",
        "\n",
        "\n",
        "> ðŸ’¡ hint: you can refer to **\"NLP Project Overview\"** and **\"NLP Project Solutions\"** in the Udemy Course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4701a5e-14f8-4c92-9957-924067841216",
      "metadata": {
        "id": "e4701a5e-14f8-4c92-9957-924067841216"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be307d30-6307-439e-8f64-cfc2d0d33ea9",
      "metadata": {
        "id": "be307d30-6307-439e-8f64-cfc2d0d33ea9"
      },
      "outputs": [],
      "source": [
        "<..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a001a2-1e9f-4399-95e8-5a967aa7c4ef",
      "metadata": {
        "id": "49a001a2-1e9f-4399-95e8-5a967aa7c4ef"
      },
      "outputs": [],
      "source": [
        "# Use 20% of the dataset as test set\n",
        "X_train, X_test, y_train, y_test = <..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe31cb0-69fa-4ccf-a610-186ec2a1d743",
      "metadata": {
        "id": "4fe31cb0-69fa-4ccf-a610-186ec2a1d743"
      },
      "outputs": [],
      "source": [
        "# instantiate the model\n",
        "nb = <..>\n",
        "\n",
        "# train the model\n",
        "<..>\n",
        "\n",
        "# generate predictions\n",
        "predictions = <..>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbc5c74-3138-4760-87de-5870fe1e7641",
      "metadata": {
        "id": "3fbc5c74-3138-4760-87de-5870fe1e7641"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test,predictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cee0be5-e0da-45d7-95de-eaa5249e342e",
      "metadata": {
        "id": "1cee0be5-e0da-45d7-95de-eaa5249e342e"
      },
      "source": [
        "### 2.6.3 Extra Contents: Train the Classification Model using TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caef33fa-52e9-4bc8-b50d-d95d293159f6",
      "metadata": {
        "id": "caef33fa-52e9-4bc8-b50d-d95d293159f6"
      },
      "outputs": [],
      "source": [
        "# TextBlob require the train and test datasets in such format:\n",
        "# train = [\n",
        "# ...     ('I love this sandwich.', 'pos'),\n",
        "# ...     ('this is an amazing place!', 'pos'),\n",
        "# ...     ('I feel very good about these beers.', 'pos'),\n",
        "# ...     ('this is my best work.', 'pos'),\n",
        "# ...     (\"what an awesome view\", 'pos'),\n",
        "# ...     ('I do not like this restaurant', 'neg'),\n",
        "# ...     ('I am tired of this stuff.', 'neg'),\n",
        "# ...     (\"I can't deal with this\", 'neg'),\n",
        "# ...     ('he is my sworn enemy!', 'neg'),\n",
        "# ...     ('my boss is horrible.', 'neg')\n",
        "# ... ]\n",
        "\n",
        "# test = [\n",
        "# ...     ('the beer was good.', 'pos'),\n",
        "# ...     ('I do not enjoy my job', 'neg'),\n",
        "# ...     (\"I ain't feeling dandy today.\", 'neg'),\n",
        "# ...     (\"I feel amazing!\", 'pos'),\n",
        "# ...     ('Gary is a friend of mine.', 'pos'),\n",
        "# ...     (\"I can't believe I'm doing this.\", 'neg')\n",
        "# ... ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b286f6c-6207-4724-86a7-7f02607b9b0b",
      "metadata": {
        "tags": [],
        "id": "1b286f6c-6207-4724-86a7-7f02607b9b0b"
      },
      "outputs": [],
      "source": [
        "# Use first 2000 rows for training; last 1000+ rows for testing\n",
        "train = df.iloc[:2000].apply(lambda x: (x.adjectives, x.target), axis=1)\n",
        "test = df.iloc[4000:].apply(lambda x: (x.adjectives, x.target), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3a5f8f-8095-49ec-84de-0b666f691712",
      "metadata": {
        "id": "4d3a5f8f-8095-49ec-84de-0b666f691712"
      },
      "outputs": [],
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "cl = NaiveBayesClassifier(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806ab48b-3cc4-4cd9-9c08-0c50d648a5e3",
      "metadata": {
        "id": "806ab48b-3cc4-4cd9-9c08-0c50d648a5e3"
      },
      "outputs": [],
      "source": [
        "cl.classify(\"I will come back for sure. Taste great!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30ca1c8-393c-4cec-b4ad-d04d2d54385b",
      "metadata": {
        "id": "b30ca1c8-393c-4cec-b4ad-d04d2d54385b"
      },
      "outputs": [],
      "source": [
        "cl.accuracy(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c3bf53-ab89-410d-a607-fb15377da2bd",
      "metadata": {
        "id": "e8c3bf53-ab89-410d-a607-fb15377da2bd"
      },
      "outputs": [],
      "source": [
        "cl.show_informative_features(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32fe6d8-b6c4-4e98-bcf4-0a480110fca5",
      "metadata": {
        "id": "b32fe6d8-b6c4-4e98-bcf4-0a480110fca5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}